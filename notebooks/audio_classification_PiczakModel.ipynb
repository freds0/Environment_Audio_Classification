{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
    "  wav,sr = librosa.load(file_path,sr=sr)\n",
    "  if wav.shape[0]<5*sr:\n",
    "    wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "  else:\n",
    "    wav=wav[:5*sr]\n",
    "  spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,\n",
    "              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "  spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "  return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_to_image(spec, eps=1e-6):\n",
    "  mean = spec.mean()\n",
    "  std = spec.std()\n",
    "  spec_norm = (spec - mean) / (std + eps)\n",
    "  spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "  spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "  spec_scaled = spec_scaled.astype(np.uint8)\n",
    "  return spec_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "class ESC50Data(Dataset):\n",
    "  def __init__(self, base, df, in_col, out_col):\n",
    "    self.df = df\n",
    "    self.data = []\n",
    "    self.labels = []\n",
    "    self.c2i={}\n",
    "    self.i2c={}\n",
    "    self.categories = sorted(df[out_col].unique())\n",
    "    for i, category in enumerate(self.categories):\n",
    "      self.c2i[category]=i\n",
    "      self.i2c[i]=category\n",
    "    for ind in tqdm(range(len(df))):\n",
    "      row = df.iloc[ind]\n",
    "      file_path = os.path.join(base,row[in_col])\n",
    "      self.data.append(spec_to_image(get_melspectrogram_db(file_path))[np.newaxis,...])\n",
    "      self.labels.append(self.c2i[row['category']])\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [00:22<00:00, 88.44it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 93.76it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/ESC-50-master/train.csv')\n",
    "valid = pd.read_csv('dataset/ESC-50-master/test.csv')\n",
    "train_data = ESC50Data('dataset/ESC-50-master/audio/', train, 'filename', 'category')\n",
    "valid_data = ESC50Data('dataset/ESC-50-master/audio/', valid, 'filename', 'category')\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128, 431])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = iter(train_loader).next()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from base import BaseModel\n",
    "\n",
    "class ESC50Model(nn.Module):\n",
    "    def __init__(self, input_shape, batch_size=16, num_cats=50):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 80, kernel_size = (57, 6), stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(80)\n",
    "        #self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(80, 80, kernel_size = (1, 3), stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(80)  \n",
    "        n1 = (input_shape[1]-57)+1        \n",
    "        n3 = ((n1 -4) / 1) + 1\n",
    "        \n",
    "        n2 = (input_shape[2]-6)+1        \n",
    "        n4 = int((n2 -3) / 3) + 1\n",
    "        \n",
    "        n5 = ((n3-1) / 1) + 1\n",
    "        n7 = ((n5 - 1) / 1) + 1        \n",
    "        \n",
    "        n6 = ((n4 - 3) / 1) + 1\n",
    "        n8 = int((n6 -3) / 3) + 1\n",
    "        n = int(n8 * n7 * 80)\n",
    "        self.dense1 = nn.Linear(n, 100)        \n",
    "        self.dense2 = nn.Linear(100, num_cats)                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=(4, 3), stride= (1,3))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=(1, 3), stride= (1,3))  \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device('cuda:0')\n",
    "else:\n",
    "  device=torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 128, 431)\n",
    "model = ESC50Model(input_shape)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 128, 431])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = iter(train_loader).next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,128, 431)\n",
    "x = torch.unsqueeze(x, dim=1)\n",
    "n = x.shape[2]*x.shape[3] \n",
    "y_hat = model(x.float().to(device))\n",
    "\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34(pretrained=True)\n",
    "model.fc = nn.Linear(512,50)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_decay(optimizer, epoch):\n",
    "  if epoch%10==0:\n",
    "    new_lr = learning_rate / (10**(epoch//10))\n",
    "    optimizer = setlr(optimizer, new_lr)\n",
    "    print(f'Changed learning rate to {new_lr}')\n",
    "  return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(torch.from_numpy(output), dim=1)\n",
    "        target = torch.from_numpy(target)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "    return correct / len(target)\n",
    "\n",
    "\n",
    "def top_k_acc(output, target, k=3):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.topk(output, k, dim=1)[1]\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            correct += torch.sum(pred[:, i] == target).item()\n",
    "    return correct / len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr=None):\n",
    "    for epoch in tqdm(range(1,epochs+1)):\n",
    "        model.train()\n",
    "        batch_losses=[]\n",
    "        if change_lr:\n",
    "            optimizer = change_lr(optimizer, epoch)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        train_losses.append(batch_losses)\n",
    "        print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1])}')\n",
    "        model.eval()\n",
    "        batch_losses=[]\n",
    "        trace_y = []\n",
    "        trace_yhat = []\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            trace_y.append(y.cpu().detach().numpy())\n",
    "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        valid_losses.append(batch_losses)\n",
    "        trace_y = np.concatenate(trace_y)\n",
    "        trace_yhat = np.concatenate(trace_yhat)\n",
    "        #accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
    "        accuracy = accuracy_fn(trace_yhat, trace_y)\n",
    "        print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1])} Valid-Accuracy : {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:14<07:09, 14.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 Train-Loss : 11.314625670811019\n",
      "Epoch - 1 Valid-Loss : 75.5243367877602 Valid-Accuracy : 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/30 [00:29<06:55, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 Train-Loss : 5.197297315200115\n",
      "Epoch - 2 Valid-Loss : 70.33436861038207 Valid-Accuracy : 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 3/30 [00:44<06:43, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 3 Train-Loss : 2.477169712022815\n",
      "Epoch - 3 Valid-Loss : 47.91774243037366 Valid-Accuracy : 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 4/30 [00:59<06:29, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 4 Train-Loss : 1.2231332085582745\n",
      "Epoch - 4 Valid-Loss : 37.59196340560913 Valid-Accuracy : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/30 [01:15<06:15, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 5 Train-Loss : 0.9090656357631113\n",
      "Epoch - 5 Valid-Loss : 38.070914583206175 Valid-Accuracy : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 6/30 [01:30<06:01, 15.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 6 Train-Loss : 0.8304071721860931\n",
      "Epoch - 6 Valid-Loss : 44.6129428678751 Valid-Accuracy : 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 7/30 [01:45<05:46, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 7 Train-Loss : 0.8552062861162018\n",
      "Epoch - 7 Valid-Loss : 32.33463901519775 Valid-Accuracy : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 8/30 [02:00<05:32, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 8 Train-Loss : 0.5476336242041054\n",
      "Epoch - 8 Valid-Loss : 37.5331032371521 Valid-Accuracy : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [02:15<05:16, 15.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 9 Train-Loss : 0.34306283500098794\n",
      "Epoch - 9 Valid-Loss : 31.077303858697416 Valid-Accuracy : 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'setlr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-419-021f1735a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-416-bf3b80eb17d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_losses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchange_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-318-bd969686aba8>\u001b[0m in \u001b[0;36mlr_decay\u001b[0;34m(optimizer, epoch)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetlr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Changed learning rate to {new_lr}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'setlr' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 30\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "\n",
    "train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
