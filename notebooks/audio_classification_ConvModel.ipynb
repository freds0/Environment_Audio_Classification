{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
    "  wav,sr = librosa.load(file_path,sr=sr)\n",
    "  if wav.shape[0]<5*sr:\n",
    "    wav=np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "  else:\n",
    "    wav=wav[:5*sr]\n",
    "  spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,\n",
    "              hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "  spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "  return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_to_image(spec, eps=1e-6):\n",
    "  mean = spec.mean()\n",
    "  std = spec.std()\n",
    "  spec_norm = (spec - mean) / (std + eps)\n",
    "  spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "  spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "  spec_scaled = spec_scaled.astype(np.uint8)\n",
    "  return spec_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "class ESC50Data(Dataset):\n",
    "  def __init__(self, base, df, in_col, out_col):\n",
    "    self.df = df\n",
    "    self.data = []\n",
    "    self.labels = []\n",
    "    self.c2i={}\n",
    "    self.i2c={}\n",
    "    self.categories = sorted(df[out_col].unique())\n",
    "    for i, category in enumerate(self.categories):\n",
    "      self.c2i[category]=i\n",
    "      self.i2c[i]=category\n",
    "    for ind in tqdm(range(len(df))):\n",
    "      row = df.iloc[ind]\n",
    "      file_path = os.path.join(base,row[in_col])\n",
    "      self.data.append(spec_to_image(get_melspectrogram_db(file_path))[np.newaxis,...])\n",
    "      self.labels.append(self.c2i[row['category']])\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1949/1949 [00:22<00:00, 87.20it/s]\n",
      "100%|██████████| 51/51 [00:00<00:00, 90.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/ESC-50-master/train.csv')\n",
    "valid = pd.read_csv('dataset/ESC-50-master/test.csv')\n",
    "train_data = ESC50Data('dataset/ESC-50-master/audio/', train, 'filename', 'category')\n",
    "valid_data = ESC50Data('dataset/ESC-50-master/audio/', valid, 'filename', 'category')\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128, 431])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = iter(train_loader).next()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from base import BaseModel\n",
    "\n",
    "class ESC50Model(nn.Module):\n",
    "    def __init__(self, input_shape, batch_size=16, num_cats=50):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.dense1 = nn.Linear(256*(((input_shape[1]//2)//2)//2)*(((input_shape[2]//2)//2)//2),500)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(500, num_cats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2) \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(self.bn6(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(self.bn8(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "if torch.cuda.is_available():\n",
    "  device=torch.device('cuda:0')\n",
    "else:\n",
    "  device=torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 128, 431)\n",
    "model = ESC50Model(input_shape)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet34(pretrained=True)\n",
    "model.fc = nn.Linear(512,50)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_decay(optimizer, epoch):\n",
    "  if epoch%10==0:\n",
    "    new_lr = learning_rate / (10**(epoch//10))\n",
    "    optimizer = setlr(optimizer, new_lr)\n",
    "    print(f'Changed learning rate to {new_lr}')\n",
    "  return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(output, target):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.argmax(torch.from_numpy(output), dim=1)\n",
    "        target = torch.from_numpy(target)\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        correct += torch.sum(pred == target).item()\n",
    "    return correct / len(target)\n",
    "\n",
    "\n",
    "def top_k_acc(output, target, k=3):\n",
    "    with torch.no_grad():\n",
    "        pred = torch.topk(output, k, dim=1)[1]\n",
    "        assert pred.shape[0] == len(target)\n",
    "        correct = 0\n",
    "        for i in range(k):\n",
    "            correct += torch.sum(pred[:, i] == target).item()\n",
    "    return correct / len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, change_lr=None):\n",
    "    for epoch in tqdm(range(1,epochs+1)):\n",
    "        model.train()\n",
    "        batch_losses=[]\n",
    "        if change_lr:\n",
    "            optimizer = change_lr(optimizer, epoch)\n",
    "        for i, data in enumerate(train_loader):\n",
    "            x, y = data\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            loss.backward()\n",
    "            batch_losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "\n",
    "        train_losses.append(batch_losses)\n",
    "        print(f'Epoch - {epoch} Train-Loss : {np.mean(train_losses[-1])}')\n",
    "        model.eval()\n",
    "        batch_losses=[]\n",
    "        trace_y = []\n",
    "        trace_yhat = []\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            x, y = data\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            trace_y.append(y.cpu().detach().numpy())\n",
    "            trace_yhat.append(y_hat.cpu().detach().numpy())      \n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "        valid_losses.append(batch_losses)\n",
    "        trace_y = np.concatenate(trace_y)\n",
    "        trace_yhat = np.concatenate(trace_yhat)\n",
    "        #accuracy = np.mean(trace_yhat.argmax(axis=1)==trace_y)\n",
    "        accuracy = accuracy_fn(trace_yhat, trace_y)\n",
    "        print(f'Epoch - {epoch} Valid-Loss : {np.mean(valid_losses[-1])} Valid-Accuracy : {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:46<00:46, 46.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 1 Train-Loss : 1.044370535860459\n",
      "Epoch - 1 Valid-Loss : 17.0052689405588 Valid-Accuracy : 0.0196078431372549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:32<00:00, 46.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 2 Train-Loss : 0.8907479321116056\n",
      "Epoch - 2 Valid-Loss : 15.718058787859404 Valid-Accuracy : 0.0784313725490196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "epochs = 2\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "\n",
    "train(model, loss_fn, train_loader, valid_loader, epochs, optimizer, train_losses, valid_losses, lr_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
